
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Tensorflow Serving Setup Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Guang Yang">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="css/website.css">
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="0x02.slim.html" />
    
    
    <link rel="prev" href="0x00.init.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://docs.docker.com/" target="_blank" class="custom-link">Docker</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        <li class="header">Overview</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Docker Image of Tensorflow Serving Inception Models
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Guide</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="0x00.init.html">
            
                <a href="0x00.init.html">
            
                    
                    Prerequisite
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="2.2" data-path="0x01.tfs.html">
            
                <a href="0x01.tfs.html">
            
                    
                    Tensorflow Serving Setup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="0x02.slim.html">
            
                <a href="0x02.slim.html">
            
                    
                    Tensorflow Serving with Tensorflow Slim Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="0x02b00.slim.inception.v4.html">
            
                <a href="0x02b00.slim.inception.v4.html">
            
                    
                    Tensorflow Serving with Slim Inception-V4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="0x02b01.slim.inception.resnet.v2.html">
            
                <a href="0x02b01.slim.inception.resnet.v2.html">
            
                    
                    Tensorflow Serving with Slim Inception-Resnet-V2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="0x02b02.slim.unified.client.html">
            
                <a href="0x02b02.slim.unified.client.html">
            
                    
                    A Unified Slim Client on PredictionService
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="0x03.rest.html">
            
                <a href="0x03.rest.html">
            
                    
                    Add REST-API via uWSGI and Nginx
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="0x03b00.rest.uwsgi.html">
            
                <a href="0x03b00.rest.uwsgi.html">
            
                    
                    uWSGI Application Setup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="0x03b01.rest.nginx.html">
            
                <a href="0x03b01.rest.nginx.html">
            
                    
                    Nginx Web Server Setup
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="0x04.docker.html">
            
                <a href="0x04.docker.html">
            
                    
                    Docker Images that Serves Tensorflow Slim Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.5.1" data-path="0x04b00.docker.grpc.html">
            
                <a href="0x04b00.docker.grpc.html">
            
                    
                    Docker Image supports gPRC + protobuf
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5.2" data-path="0x04b01.docker.rest.html">
            
                <a href="0x04b01.docker.rest.html">
            
                    
                    Docker Image supports gPRC + protobuf, and REST + JSON
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Miscellaneous</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="0xff.misc.html">
            
                <a href="0xff.misc.html">
            
                    
                    Miscellaneous
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="0xffb00.misc.github.html">
            
                <a href="0xffb00.misc.github.html">
            
                    
                    Github
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="0xffb00.misc.tensorflow.html">
            
                <a href="0xffb00.misc.tensorflow.html">
            
                    
                    Tensorflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="0xffb00.misc.uwsgi.nginx.html">
            
                <a href="0xffb00.misc.uwsgi.nginx.html">
            
                    
                    uWSGI + Nginx
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="0xffb00.misc.docker.html">
            
                <a href="0xffb00.misc.docker.html">
            
                    
                    Docker
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="4.1" >
            
                <a target="_blank" href="https://github.com/gyang274/">
            
                    
                    yg
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Tensorflow Serving Setup</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="tensorflow-serving-setup">Tensorflow Serving Setup</h1>
<h2 id="install-tensorflow-serving-from-source">Install Tensorflow Serving from Source</h2>
<ul>
<li>clone the repo</li>
</ul>
<pre><code>$ mkdir src

$ cd src

$ git clone --recurse-submodules https://github.com/tensorflow/serving

$ cd serving
</code></pre><ul>
<li>configurate tensorflow</li>
</ul>
<pre><code>$ cd tensorflow

./configure

$ cd ..
</code></pre><h2 id="build-tensorflow-serving-model-servers-and-example-models">Build Tensorflow Serving Model Servers and Example Models</h2>
<ul>
<li>build the tensorflow serving model servers</li>
</ul>
<pre><code># build server (tensorflow serving server)

$ bazel build -c opt //tensorflow_serving/model_servers:tensorflow_model_server

# build server with customized output_user_root

$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/model_servers:tensorflow_model_server
</code></pre><ul>
<li>build the tensorflow serving example models</li>
</ul>
<pre><code># build models (tensorflow serving example models)

$ export PYTHON_LIB_PATH=...

$ export PYTHON_LIB_PATH=/home/yg/anaconda2/lib/python2.7/site-packages

$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/example/[...]

$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/example:mnist_saved_model

$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/example:inception_saved_model
</code></pre><ul>
<li>build the tensorflow serving example models clients</li>
</ul>
<pre><code>$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/example:mnist_client

$ bazel --output_user_root=./tf_bazel_cache/ build -c opt //tensorflow_serving/example:inception_client
</code></pre><h2 id="inspect-tensorflow-serving-example-models">Inspect Tensorflow Serving Example Models</h2>
<h3 id="mnistsavedmodel"><code>mnist_saved_model</code></h3>
<p>mnist_saved_model include a training phase, whereas inception models, and customized models like we will implemented often recover the network from a pre-trained and pre-saved checkpoint.</p>
<ul>
<li>setup saved model as servable</li>
</ul>
<pre><code># run mnist_saved_model to export freezed graph and weights for serving

# check ./tensorflow_serving/example/mnist_saved_model.py for options

$ bazel-bin/tensorflow_serving/example/mnist_saved_model \
    [--training_iteration=x] \
    [--model_version=y] \
    export_dir

$ mkdir -p tf_servables/mnist

$ bazel-bin/tensorflow_serving/example/mnist_saved_model \
    --training_iteration=1000 \
    --model_version=1 \
    tf_servables/mnist
</code></pre><ul>
<li>serve</li>
</ul>
<pre><code># use tensorflow_model_server to serve model servable 

$ bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server [...]

# note --model_base_path requires an absolute path, so use environment variable $PWD to provide an absolute path prefix

$ bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \
    --model_name=mnist \
    --model_base_path=$PWD/tf_servables/mnist/ \
    --port=9000
</code></pre><ul>
<li>client</li>
</ul>
<pre><code># open another terminal (ctrl + alt + t)

$ bazel-bin/tensorflow_serving/example/mnist_client \
    --server=localhost:9000 \
    --num_tests=1000
</code></pre><ul>
<li>tensorflow_model_server auto-discovers new versions</li>
</ul>
<pre><code># run mnist_saved_model again to export a new model version

# keep the tensorflow model server serving the mnist saved model 

$ bazel-bin/tensorflow_serving/example/mnist_saved_model \
    --training_iteration=2000 \
    --model_version=2 \
    tf_servables/mnist

# an updated freezed graph and weights for serving is available

$ ls tf_servables/mnist
&gt; 1 2

# back to the terminal on tensorflow model server serving mnist
&gt; : I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: mnist version: 2}
&gt; : I tensorflow_serving/core/loader_harness.cc:137] Quiescing servable version {name: mnist version: 1}
&gt; : I tensorflow_serving/core/loader_harness.cc:144] Done quiescing servable version {name: mnist version: 1}
&gt; : I tensorflow_serving/core/loader_harness.cc:119] Unloading servable version {name: mnist version: 1}
&gt; : I ./tensorflow_serving/core/simple_loader.h:294] Calling MallocExtension_ReleaseToSystem() after servable unload with 60736
&gt; : I tensorflow_serving/core/loader_harness.cc:127] Done unloading servable version {name: mnist version: 1}

$ bazel-bin/tensorflow_serving/example/mnist_client \
    --server=localhost:9000 \
    --num_tests=1000
</code></pre><h3 id="inception-v3"><code>inception-v3</code></h3>
<p><code>inception_saved_model</code> requires a pre-trained and pre-saved checkpoint on inception-v3 model</p>
<ul>
<li>download google published inception-v3 checkpoint file</li>
</ul>
<pre><code># an investigation follow the path

- ./tensorflow_serving/example/BUILD
...
py_binary(
    name = &quot;inception_saved_model&quot;,
    srcs = [
        &quot;inception_saved_model.py&quot;,
    ],
    srcs_version = &quot;PY2AND3&quot;,
    deps = [
        &quot;@inception_model//inception&quot;,
        &quot;@org_tensorflow//tensorflow:tensorflow_py&quot;,
    ],
)
...

- ./tensorflow_serving/workspace.bzl
...
def tf_serving_workspace():
  native.new_local_repository(
      name = &quot;inception_model&quot;,
      path = &quot;tf_models/research/inception&quot;,
      build_file = &quot;tf_models/research/inception/inception/BUILD&quot;,
  )
  ...
...

# so, this inception-v3 is defined at ./tf_models/research/inception


# in order to make it clear, there are at leaset two places where inception-v3 is defined
# one is defined at ./tf_models/research/inception, which uses slim module, 
# another is defined at ./tf_models/research/slim, which includes a model inception-v3 
# and these two models are slightly different, so model definition must match to the checkpoint downloaded

# see https://github.com/tensorflow/models/tree/master/research/inception
# model ./tf_models/research/inception match to checkpoint http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz

# see https://github.com/tensorflow/models/tree/master/research/slim
# model ./tf_models/research/slim match to checkpoint http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz
</code></pre><pre><code>$ mkdir -p tf_checkpoints/inception

$ wget -O tf_checkpoints/inception/inception-v3-2016-03-01.tar.gz http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz

$ tar -xvzf tf_checkpoints/inception/inception-v3-2016-03-01.tar.gz -C tf_checkpoints/inception

$ ls tf_checkpoints/inception/inception-v3
&gt; checkpoint  model.ckpt-157585  README.txt

$ rm tf_checkpoints/inception/inception-v3-2016-03-01.tar.gz
</code></pre><pre><code># check ./tensorflow_serving/example/inception_saved_model.py for options

# ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir) is called in 
# ./tensorflow_serving/example/inception_saved_model.py to get checkpoint
# status and model_checkpoint_path, which require a file named checkpoint  
# in the checkpoint_dir to process. 

# create a checkpoint file if not present

$ echo &apos;model_checkpoint_path: &quot;model.ckpt-157585&quot;&apos; &gt; ./tf_checkpoints/inception/inception-v3/checkpoint
</code></pre><ul>
<li>inspect checkpoint file</li>
</ul>
<pre><code># https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py

$ cd tensorflow

$ bazel --output_user_root=../tf_bazel_cache build -c opt //tensorflow/python/tools:inspect_checkpoint

$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=../tf_checkpoints/inception/inception-v3/model.ckpt-157585

$ cd ..
</code></pre><ul>
<li>setup saved model as servable</li>
</ul>
<pre><code># check ./tensorflow_serving/example/inception_saved_model.py for options

$ mkdir -p tf_servables/inception/inception-v3

$ bazel-bin/tensorflow_serving/example/inception_saved_model \
    --checkpoint_dir=tf_checkpoints/inception/inception-v3 \
    --output_dir=tf_servables/inception/inception-v3 \
    --model_version=1 \
    --image_size=299
</code></pre><ul>
<li>serve</li>
</ul>
<pre><code># check ./tensorflow_serving/example/inception_saved_model.py for options

$ bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server [...]

# --model_name=inception from ./tensorflow_serving/example/BUILD
# --model_base_path=/an/absolute/path/ from previous bazel build on setup model servables
# --port=9090 since mnist is running on 9000

$ bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \
    --model_name=inception \
    --model_base_path=$PWD/tf_servables/inception/inception-v3 \
    --port=9090
</code></pre><ul>
<li>client</li>
</ul>
<pre><code># check ./tensorflow_serving/example/inception_client.py for options

$ bazel-bin/tensorflow_serving/example/inception_client \
    --server=localhost:9000 \
    --image=/path/to/my_favoriate_image.jpg
</code></pre><h2 id="blind-build-and-test-all-nodo">Blind Build and Test All (NODO)</h2>
<pre><code>$ bazel build tensorflow_serving/...

$ bazel test tensorflow_serving/...
</code></pre>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="0x00.init.html" class="navigation navigation-prev " aria-label="Previous page: Prerequisite">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="0x02.slim.html" class="navigation navigation-next " aria-label="Next page: Tensorflow Serving with Tensorflow Slim Models">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Tensorflow Serving Setup","level":"2.2","depth":1,"next":{"title":"Tensorflow Serving with Tensorflow Slim Models","level":"2.3","depth":1,"path":"0x02.slim.md","ref":"0x02.slim.md","articles":[{"title":"Tensorflow Serving with Slim Inception-V4","level":"2.3.1","depth":2,"path":"0x02b00.slim.inception.v4.md","ref":"0x02b00.slim.inception.v4.md","articles":[]},{"title":"Tensorflow Serving with Slim Inception-Resnet-V2","level":"2.3.2","depth":2,"path":"0x02b01.slim.inception.resnet.v2.md","ref":"0x02b01.slim.inception.resnet.v2.md","articles":[]},{"title":"A Unified Slim Client on PredictionService","level":"2.3.3","depth":2,"path":"0x02b02.slim.unified.client.md","ref":"0x02b02.slim.unified.client.md","articles":[]}]},"previous":{"title":"Prerequisite","level":"2.1","depth":1,"path":"0x00.init.md","ref":"0x00.init.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"root":"./src","styles":{"website":"css/website.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"Guang Yang","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"links":{"sidebar":{"Docker":"https://docs.docker.com/"}},"gitbook":"*"},"file":{"path":"0x01.tfs.md","mtime":"2017-10-20T17:56:29.846Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-01-02T05:03:05.863Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

