
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Tensorflow Serving with Slim Inception-V4 Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Guang Yang">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="css/website.css">
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="0x02b01.slim.inception.resnet.v2.html" />
    
    
    <link rel="prev" href="0x02.slim.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://docs.docker.com/" target="_blank" class="custom-link">Docker</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        <li class="header">Overview</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Docker Image of Tensorflow Serving Inception Models
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Guide</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="0x00.init.html">
            
                <a href="0x00.init.html">
            
                    
                    Prerequisite
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="0x01.tfs.html">
            
                <a href="0x01.tfs.html">
            
                    
                    Tensorflow Serving Setup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="0x02.slim.html">
            
                <a href="0x02.slim.html">
            
                    
                    Tensorflow Serving with Tensorflow Slim Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="2.3.1" data-path="0x02b00.slim.inception.v4.html">
            
                <a href="0x02b00.slim.inception.v4.html">
            
                    
                    Tensorflow Serving with Slim Inception-V4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="0x02b01.slim.inception.resnet.v2.html">
            
                <a href="0x02b01.slim.inception.resnet.v2.html">
            
                    
                    Tensorflow Serving with Slim Inception-Resnet-V2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="0x02b02.slim.unified.client.html">
            
                <a href="0x02b02.slim.unified.client.html">
            
                    
                    A Unified Slim Client on PredictionService
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="0x03.rest.html">
            
                <a href="0x03.rest.html">
            
                    
                    Add REST-API via uWSGI and Nginx
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="0x03b00.rest.uwsgi.html">
            
                <a href="0x03b00.rest.uwsgi.html">
            
                    
                    uWSGI Application Setup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="0x03b01.rest.nginx.html">
            
                <a href="0x03b01.rest.nginx.html">
            
                    
                    Nginx Web Server Setup
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="0x04.docker.html">
            
                <a href="0x04.docker.html">
            
                    
                    Docker Images that Serves Tensorflow Slim Models
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.5.1" data-path="0x04b00.docker.grpc.html">
            
                <a href="0x04b00.docker.grpc.html">
            
                    
                    Docker Image supports gPRC + protobuf
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5.2" data-path="0x04b01.docker.rest.html">
            
                <a href="0x04b01.docker.rest.html">
            
                    
                    Docker Image supports gPRC + protobuf, and REST + JSON
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Miscellaneous</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="0xff.misc.html">
            
                <a href="0xff.misc.html">
            
                    
                    Miscellaneous
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="0xffb00.misc.github.html">
            
                <a href="0xffb00.misc.github.html">
            
                    
                    Github
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="0xffb00.misc.tensorflow.html">
            
                <a href="0xffb00.misc.tensorflow.html">
            
                    
                    Tensorflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="0xffb00.misc.uwsgi.nginx.html">
            
                <a href="0xffb00.misc.uwsgi.nginx.html">
            
                    
                    uWSGI + Nginx
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="0xffb00.misc.docker.html">
            
                <a href="0xffb00.misc.docker.html">
            
                    
                    Docker
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="4.1" >
            
                <a target="_blank" href="https://github.com/gyang274/">
            
                    
                    yg
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Tensorflow Serving with Slim Inception-V4</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="tensorflow-serving-with-slim-inception-v4">Tensorflow Serving with Slim Inception-V4</h2>
<h3 id="prerequisite">Prerequisite</h3>
<p>To use model definition in ./tf_models/research/slim, we need to first make slim nets public visible,
and then add slim as local repository to tensorflow serving bazel workspace. </p>
<ul>
<li>make slim nets as public visible</li>
</ul>
<pre><code># format of edit file ./tf_models/research/slim/BUILD with following chages

# add visibility = [&quot;//visibility:public&quot;] into py_library()

- ./tf_models/research/slim/BUILD
...
py_library(
    name = &quot;dataset_factory&quot;,
    srcs = [&quot;datasets/dataset_factory.py&quot;],
    deps = [
        &quot;:cifar10&quot;,
        &quot;:flowers&quot;,
        &quot;:imagenet&quot;,
        &quot;:mnist&quot;,
    ],
    visibility = [&quot;//visibility:public&quot;],
)

py_library(
    name = &quot;preprocessing_factory&quot;,
    srcs = [&quot;preprocessing/preprocessing_factory.py&quot;],
    deps = [
        &quot;:cifarnet_preprocessing&quot;,
        &quot;:inception_preprocessing&quot;,
        &quot;:lenet_preprocessing&quot;,
        &quot;:vgg_preprocessing&quot;,
    ],
    visibility = [&quot;//visibility:public&quot;],
)

py_library(
    name = &quot;nets&quot;,
    deps = [
        &quot;:alexnet&quot;,
        &quot;:cifarnet&quot;,
        &quot;:inception&quot;,
        &quot;:lenet&quot;,
        &quot;:mobilenet_v1&quot;,
        &quot;:overfeat&quot;,
        &quot;:resnet_v1&quot;,
        &quot;:resnet_v2&quot;,
        &quot;:vgg&quot;,
    ],
    visibility = [&quot;//visibility:public&quot;],
)
...

# and comment out all deps to //tensorflow in this build file

- ./tf_models/research/slim/BUILD
...
py_library(
    name = &quot;dataset_utils&quot;,
    srcs = [&quot;datasets/dataset_utils.py&quot;],
    deps = [
        # &quot;//tensorflow&quot;,
    ],
)
...
</code></pre><ul>
<li>add slim as local repository to tensorflow serving bazel workspace</li>
</ul>
<pre><code>- ./tensorflow_serving/workspace.bzl
...
def tf_serving_workspace():
  native.new_local_repository(
    name = &quot;inception_model&quot;,
    path = &quot;tf_models/inception&quot;,
    build_file = &quot;tf_models/inception/inception/BUILD&quot;,
  )

  native.new_local_repository(
    name = &quot;slim_model&quot;,
    path = &quot;tf_models/research/slim&quot;,
    build_file = &quot;tf_models/research/slim/BUILD&quot;,
  )

  tf_workspace(path_prefix = &quot;&quot;, tf_repo_name = &quot;org_tensorflow&quot;)
  ...
...
</code></pre><p>In this way, the scripts in ./tensorflow_serving can understand the dataset, preprocessing and nests 
defined in ./tf_models/research/slim.</p>
<h3 id="sliminceptionv4savedmodelpy"><code>slim_inception_v4_saved_model.py</code></h3>
<p>Just like <code>./tensorflow_serving/example/mnist_saved_model.py</code> and <code>./tensorflow_serving/example/inception_saved_model.py</code>,
we want to add our own <code>./tensorflow_serving/example/slim_inception_v4_saved_model.py</code>.</p>
<p>This script should load pre-trained pre-saved slim-inception-v4 checkpoints, and create a model servable,
in a simliar way of the script <code>inception_v3_saved_model.py</code>.</p>
<p>Of course, the <code>slim_inception_v4_saved_model.py</code> script depends on the dataset, preprocessing and nets defined in 
<code>./tf_models/research/slim</code>. These dataset, preprocessing and nets are now available in the <code>./tensorflow_serving</code>
workspace, as a result of previous prerequisite step. However, we still need to declare the dependence in 
<code>./tensorflow_serving/example/BUILD</code>, so that in the <code>./tensorflow_serving/example/slim_inception_v4_saved_model.py</code>,
the environment is aware of dataset, preprocessing and nets.</p>
<ul>
<li>add slim_inception_v4_saved_model deps in example&apos;s BUILD</li>
</ul>
<pre><code>- ./tensorflow_serving/example/BUILD
...
py_binary(
    name = &quot;slim_inception_v4_saved_model&quot;,
    srcs = [
        &quot;slim_inception_v4_saved_model.py&quot;,
    ],
    srcs_version = &quot;PY2AND3&quot;,
    deps = [
        &quot;@slim_model//:dataset_factory&quot;,
        &quot;@slim_model//:preprocessing_factory&quot;,
        &quot;@slim_model//:nets&quot;,
        &quot;@org_tensorflow//tensorflow:tensorflow_py&quot;,
    ],
)
...
</code></pre><ul>
<li>load slim modules in slim_inception_v4_saved_model.py</li>
</ul>
<pre><code>- ./tensorflow_serving/example/slim_inception_v4_saved_model.py
...
import tensorflow as tf

from datasets import imagenet

from preprocessing import inception_preprocessing

from nets import inception
...
</code></pre><ul>
<li>create slim inception v4 saved model target</li>
</ul>
<pre><code>- ./tensorflow_serving/example/slim_inception_v4_saved_model.py

# note: we output not only top 5 classes and scores, but also the last layer before the output layer,
# which can be considered as the features of an image extracted by the model for making prediction. 

...
# flexible to retrieve any tensor on graph
prelogits = sess.graph.get_tensor_by_name(
  &apos;InceptionV4/Logits/PreLogitsFlatten/flatten/Reshape:0&apos;
)
# an optional alternative to get predefined outputs
# prelogits = end_points[&apos;PreLogitsFlatten&apos;]
...

...
builder.add_meta_graph_and_variables(
  sess, [tf.saved_model.tag_constants.SERVING],
  signature_def_map={
    &apos;predict_images&apos;:
      prediction_signature,
  },
  legacy_init_op=legacy_init_op
)
...
</code></pre><ul>
<li>download pre-trained pre-saved slim-inception-v4 weights</li>
</ul>
<pre><code># download pre-trained pre-saved slim-inception-v4 weights

$ mkdir -p tf_checkpoints/slim/inception-v4

$ wget -O tf_checkpoints/slim/inception-v4/inception_v4_2016_09_09.tar.gz http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz

$ tar -tvsf tf_checkpoints/slim/inception-v4/inception_v4_2016_09_09.tar.gz

$ tar -xvzf tf_checkpoints/slim/inception-v4/inception_v4_2016_09_09.tar.gz -C tf_checkpoints/slim/inception-v4

$ ls tf_checkpoints/slim/inception-v4
&gt; inception_v4_2016_09_09.tar.gz  inception_v4.ckpt

$ rm tf_checkpoints/slim/inception-v4/inception_v4_2016_09_09.tar.gz

# inspect the checkpoint

$ cd tensorflow

$ bazel --output_user_root=../tf_bazel_cache build -c opt //tensorflow/python/tools:inspect_checkpoint

$ cd ..

$ ./tensorflow/bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=./tf_checkpoints/slim/inception-v4/inception_v4.ckpt
</code></pre><ul>
<li>setup saved model as servable</li>
</ul>
<pre><code>$ bazel --output_user_root=./tf_bazel_cache build -c opt //tensorflow_serving/example:slim_inception_v4_saved_model

$ bazel-bin/tensorflow_serving/example/slim_inception_v4_saved_model \
    --checkpoint_dir=tf_checkpoints/slim/inception-v4 \
    --output_dir=tf_servables/slim/inception-v4 \
    --model_version=1 \
    --image_size=299
</code></pre><ul>
<li>serve</li>
</ul>
<pre><code>$ bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \
    --model_name=slim_inception_v4 \
    --model_base_path=$PWD/tf_servables/slim/inception-v4 \
    --port=9000
</code></pre><h3 id="sliminceptionv4clientpy"><code>slim_inception_v4_client.py</code></h3>
<p>As slim inception v4 is served via tensorflow model server, we need a client to call the model, 
receive and present the response.</p>
<p>Just like <code>./tensorflow_serving/example/mnist_client.py</code> and <code>./tensorflow_serving/example/inception_client.py</code>,
we want to add our own <code>./tensorflow_serving/example/slim_inception_v4_client.py</code>.</p>
<p>This script should expect an image_url from users, instead of a local file path. Then, it will
read the image_url as image_bytes, send to served slim inception v4 model, receive and present
the response. </p>
<ul>
<li>add slim_inception_v4_client deps in example&apos;s BUILD</li>
</ul>
<pre><code>- ./tensorflow_serving/example/BUILD

...
py_binary(
    name = &quot;slim_inception_v4_client&quot;,
    srcs = [
        &quot;slim_inception_v4_client.py&quot;,
    ],
    srcs_version = &quot;PY2AND3&quot;,
    deps = [
        &quot;//tensorflow_serving/apis:predict_proto_py_pb2&quot;,
        &quot;//tensorflow_serving/apis:prediction_service_proto_py_pb2&quot;,
        &quot;@org_tensorflow//tensorflow:tensorflow_py&quot;,
    ],
)
...
</code></pre><ul>
<li>create slim inception v4 client target</li>
</ul>
<pre><code>- ./tensorflow_serving/example/slim_inception_v4_client.py
...
def main(_):
  ...
  image_bytes = urllib2.urlopen(FLAGS.image_url).read()
  ...
  request.inputs[&apos;images&apos;].CopyFrom(
    tf.contrib.util.make_tensor_proto(
      image_bytes, shape=[1]
    )
  )
...
</code></pre><ul>
<li>client</li>
</ul>
<pre><code>$ bazel --output_user_root=./tf_bazel_cache build -c opt //tensorflow_serving/example:slim_inception_v4_client

$ bazel-bin/tensorflow_serving/example/slim_inception_v4_client \
    --server=localhost:9000 \
    --image_url=/url/to/my_favoriate_image.jpg
</code></pre><pre><code>$ bazel-bin/tensorflow_serving/example/slim_inception_v4_client \
    --server=localhost:9000 \
    --image_url=https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg

... 
outputs {
  key: &quot;classes&quot;
  value {
    dtype: DT_STRING
    tensor_shape {
      dim {
        size: 1
      }
      dim {
        size: 5
      }
    }
    string_val: &quot;school bus&quot;
    string_val: &quot;wooden spoon&quot;
    string_val: &quot;burrito&quot;
    string_val: &quot;stupa, tope&quot;
    string_val: &quot;amphibian, amphibious vehicle&quot;
  }
}
outputs {
  key: &quot;prelogits&quot;
  value {
    dtype: DT_FLOAT
    tensor_shape {
      dim {
        size: 1
      }
      dim {
        size: 1536
      }
    }
    float_val: 0.229630336165
    float_val: 0.012188008055
    float_val: 0.890766382217
    ...
    float_val: 0.010527072474
    float_val: 0.118053443730
    float_val: 0.0
  }
}
outputs {
  key: &quot;scores&quot;
  value {
    dtype: DT_FLOAT
    tensor_shape {
      dim {
        size: 1
      }
      dim {
        size: 5
      }
    }
    float_val: 0.99850153923
    float_val: 0.00031825833139
    float_val: 8.37764491735e-06
    float_val: 8.29482996778e-06
    float_val: 7.34377454137e-06
  }
}
...
</code></pre>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="0x02.slim.html" class="navigation navigation-prev " aria-label="Previous page: Tensorflow Serving with Tensorflow Slim Models">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="0x02b01.slim.inception.resnet.v2.html" class="navigation navigation-next " aria-label="Next page: Tensorflow Serving with Slim Inception-Resnet-V2">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Tensorflow Serving with Slim Inception-V4","level":"2.3.1","depth":2,"next":{"title":"Tensorflow Serving with Slim Inception-Resnet-V2","level":"2.3.2","depth":2,"path":"0x02b01.slim.inception.resnet.v2.md","ref":"0x02b01.slim.inception.resnet.v2.md","articles":[]},"previous":{"title":"Tensorflow Serving with Tensorflow Slim Models","level":"2.3","depth":1,"path":"0x02.slim.md","ref":"0x02.slim.md","articles":[{"title":"Tensorflow Serving with Slim Inception-V4","level":"2.3.1","depth":2,"path":"0x02b00.slim.inception.v4.md","ref":"0x02b00.slim.inception.v4.md","articles":[]},{"title":"Tensorflow Serving with Slim Inception-Resnet-V2","level":"2.3.2","depth":2,"path":"0x02b01.slim.inception.resnet.v2.md","ref":"0x02b01.slim.inception.resnet.v2.md","articles":[]},{"title":"A Unified Slim Client on PredictionService","level":"2.3.3","depth":2,"path":"0x02b02.slim.unified.client.md","ref":"0x02b02.slim.unified.client.md","articles":[]}]},"dir":"ltr"},"config":{"plugins":[],"root":"./src","styles":{"website":"css/website.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"Guang Yang","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"links":{"sidebar":{"Docker":"https://docs.docker.com/"}},"gitbook":"*"},"file":{"path":"0x02b00.slim.inception.v4.md","mtime":"2017-10-30T05:57:50.350Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2017-10-30T06:30:40.490Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

