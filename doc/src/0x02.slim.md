# Tensorflow Serving with Tensorflow Slim Models

## Overview

Here comes the interesting part! 

In previous section, we trained, built and served models such as mnist, inception-v3 that comes 
with the tensorflow serving. In this section, however, we will build and serve customized models. 

To keep it simple and clear, we will use pre-defined ./tf_models/research/slim/nets/inception-v4
and ./tf_models/research/slim/nets/inception-resnet-v2 models as examples.

This approach should works with all models defined in ./tf_models/research/slim/nets, such as 
inception, inception-resnet, resnet, vgg, and mobilenet. A full list of models and versions 
can be found at https://github.com/tensorflow/models/tree/master/research/slim. 

Let's start!

## [Tensorflow Serving with Slim Inception-V4](0x02b00.slim.inception.v4.md)

## [Tensorflow Serving with Slim Inception-Resnet-V2](0x02b01.slim.inception.resnet.v2.md)

## [A Unified Slim Client on PredictionService](0x02b02.slim.unified.client.md)

